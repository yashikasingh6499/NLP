{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# I. Rule-based and Statistical Approaches for Part-of-Speech Tagging\n",
        "\n",
        "Part-of-Speech tagging, also known as POS tagging, is the process of assigning grammatical tags or labels to words in a sentence. The tags represent the syntactic category or part of speech of each word, such as noun, verb, adjective, adverb, etc. POS tagging is an essential step in many Natural Language Processing (NLP) tasks, including parsing, machine translation, and information retrieval.\n",
        "\n",
        "POS tagging can be approached using different techniques, including rule-based approaches, statistical approaches, and hybrid approaches that combine both. In statistical approaches, Hidden Markov Models (HMMs) and Maximum Entropy Markov Models (MEMMs) are commonly used.\n",
        "\n",
        "Implement a rule-based part-of-speech (POS) tagger:\n",
        "* a. Write a set of rules to assign POS tags to words based on their context\n",
        "* b. Apply the rules to a sample text and evaluate the accuracy of the tagger.\n",
        "\n",
        "\n",
        "\n",
        "Implement a statistical POS tagger using a pre-trained model:\n",
        "\n",
        "\n",
        "* a. Train a statistical POS tagger on a labeled corpus using a machine learning algorithm such as Naive Bayes or Maximum Entropy.\n",
        "* b. Apply the trained model to tag a sample text and evaluate its accuracy.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4Q05trEvPpQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "nltk.download('treebank')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker') #The maxent_ne_chunker contains two pre-trained English named entity chunkers trained on an ACE corpus (perhaps ACE ACE 2004 Multilingual Training Corpus?)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ2RhiyPSCv6",
        "outputId": "1e6fba83-3a49-4d79-d49d-f5c1bca8d791"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "gXSDBSDaPY12"
      },
      "outputs": [],
      "source": [
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import treebank\n",
        "from nltk.tag import DefaultTagger, UnigramTagger, BigramTagger #important for POS tagging\n",
        "\n",
        "# Part 1: Rule-based and Statistical Approaches for Part-of-Speech Tagging\n",
        "\n",
        "# Rule-based POS Tagger\n",
        "def rule_based_pos_tagger(sentence):\n",
        "    # Define your rules here\n",
        "    rules = [\n",
        "          (re.compile(r'\\bThe\\b'), 'DT'),\n",
        "          (re.compile(r'\\bcat\\b'), 'NN'),\n",
        "          (re.compile(r'\\bis\\b'), 'VB'),\n",
        "          (re.compile(r'\\bsitting\\b'), 'VB'),\n",
        "          (re.compile(r'\\bon\\b'), 'IN'),\n",
        "          (re.compile(r'\\bthe\\b'), 'DT'),\n",
        "          (re.compile(r'\\bmat\\b'), 'NN'),\n",
        "      ]\n",
        "    tagged_sentence = []\n",
        "    words = word_tokenize(sentence)\n",
        "    for word in words:\n",
        "        for pattern, tag in rules:\n",
        "            if pattern.match(word):\n",
        "                tagged_sentence.append((word, tag))\n",
        "                break\n",
        "        else:\n",
        "            tagged_sentence.append((word, 'UNKNOWN'))\n",
        "    return tagged_sentence\n",
        "\n",
        "# Statistical POS Tagger\n",
        "def statistical_pos_tagger(sentence):\n",
        "    # Train your model on a labeled corpus (e.g., treebank)\n",
        "    train_data = treebank.tagged_sents()[:3000]\n",
        "    # Train your statistical model here\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    train_size = int(len(train_data) * 0.8)\n",
        "    train_set = train_data[:train_size]\n",
        "    test_set = train_data[train_size:]\n",
        "\n",
        "    # Create taggers\n",
        "    default_tagger = DefaultTagger('NN')  # Default tagger assigns 'NN' to all words\n",
        "    unigram_tagger = UnigramTagger(train_set, backoff=default_tagger)  # Unigram tagger using training set\n",
        "    bigram_tagger = BigramTagger(train_set, backoff=unigram_tagger)  # Bigram tagger using training set and fallback to unigram tagger\n",
        "\n",
        "    # Evaluate on test set\n",
        "    accuracy = bigram_tagger.accuracy(test_set)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "\n",
        "    # Apply the trained model to tag the sentence\n",
        "    tagged_sentence  = bigram_tagger.tag(word_tokenize(sentence))\n",
        "    #tagged_sentence = nltk.pos_tag(words)\n",
        "    #tagged_sentence.append(tagged_sentence)\n",
        "    return tagged_sentence"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQrw3cuYOq_n"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1: Rule-based and Statistical Approaches for Part-of-Speech Tagging\n",
        "sample_sentence = \"The cat is sitting on the mat.\"\n",
        "\n",
        "# Rule-based POS Tagging\n",
        "rule_based_tags = rule_based_pos_tagger(sample_sentence)\n",
        "print(\"Rule-based POS Tags:\")\n",
        "print(rule_based_tags)\n",
        "\n",
        "# Statistical POS Tagging\n",
        "statistical_tags = statistical_pos_tagger(sample_sentence)\n",
        "print(\"Statistical POS Tags:\")\n",
        "print(statistical_tags)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exUD_vjjR6T7",
        "outputId": "78ca8b33-f21b-480c-d8dc-58b4c032881d"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule-based POS Tags:\n",
            "[('The', 'DT'), ('cat', 'NN'), ('is', 'VB'), ('sitting', 'VB'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', 'UNKNOWN')]\n",
            "Accuracy: 0.8748033560566335\n",
            "Statistical POS Tags:\n",
            "[('The', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally, NLTK has a built in function call ```pos_tags``\n",
        "See example below"
      ],
      "metadata": {
        "id": "zoASyaNWdgYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_sentence = \"The cat is sitting on the mat.\"\n",
        "\n",
        "tagged_sentence = nltk.pos_tag(word_tokenize(sample_sentence))\n",
        "print(tagged_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYSqHPf4dpMS",
        "outputId": "aba182e8-5614-49bb-ce7a-0e8fef279753"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('cat', 'NN'), ('is', 'VBZ'), ('sitting', 'VBG'), ('on', 'IN'), ('the', 'DT'), ('mat', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Exercise\n",
        "\n",
        "Update the Rule-based tagger with patterns using regex. An example could be:\n",
        "\n",
        "\n",
        "\n",
        "      ```  (r'\\b\\w+s\\b|\\b\\w+es\\b', 'NN'),     # Nouns ending ```\n",
        "\n",
        "  From here proivde an updated rule-based tagger and statistical based tagger that can apply a part of speech tag for the following complex sentence:\n",
        "\n",
        "  ```\n",
        "  sentence = \"The quick brown fox jumps over the lazy dog while it's raining heavily.\"\n",
        "\n",
        "  ```"
      ],
      "metadata": {
        "id": "S9jgjuE4euOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### START CODE ####\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "from nltk.classify.util import accuracy as nltk_accuracy\n",
        "from nltk.tag import ClassifierBasedPOSTagger\n",
        "\n",
        "# Updated Rule-based POS Tagger\n",
        "def updated_rule_based_pos_tagger(sentence):\n",
        "\n",
        "    rules = [\n",
        "        (re.compile(r'\\bthe\\b', re.IGNORECASE), 'DT'),\n",
        "        (re.compile(r'\\bquick\\b'), 'JJ'),\n",
        "        (re.compile(r'\\bbrown\\b'), 'JJ'),\n",
        "        (re.compile(r'\\bfox\\b'), 'NN'),\n",
        "        (re.compile(r'\\bjumps\\b'), 'VBZ'),\n",
        "        (re.compile(r'\\bover\\b'), 'IN'),\n",
        "        (re.compile(r'\\blazy\\b'), 'JJ'),\n",
        "        (re.compile(r'\\bdog\\b'), 'NN'),\n",
        "        (re.compile(r'\\bwhile\\b'), 'IN'),\n",
        "        (re.compile(r'\\bit\\b'), 'PRP'),\n",
        "        (re.compile(r'\\bis\\b'), 'VBZ'),\n",
        "        (re.compile(r\"'s\"), 'VBZ'),\n",
        "        (re.compile(r'\\braining\\b'), 'VBG'),\n",
        "        (re.compile(r'\\bheavily\\b'), 'RB'),\n",
        "        (re.compile(r'\\b\\w+s\\b|\\b\\w+es\\b', ), 'NN'), # Nouns ending\n",
        "        (re.compile(r'[.!?]'), '.'),                 # Punctuation\n",
        "    ]\n",
        "    tagged_sentence = []\n",
        "    words = word_tokenize(sentence)\n",
        "    for word in words:\n",
        "        for pattern, tag in rules:\n",
        "            if pattern.match(word):\n",
        "                tagged_sentence.append((word, tag))\n",
        "                break\n",
        "        else:\n",
        "            tagged_sentence.append((word, 'UNKNOWN'))\n",
        "    return tagged_sentence\n",
        "\n",
        "# Statistical POS Tagger\n",
        "\n",
        "# Function to define features for the tagger\n",
        "def word_features(words, index):\n",
        "    return {\n",
        "        'word': words[index],\n",
        "        'is_first': index == 0,\n",
        "        'is_last': index == len(words) - 1,\n",
        "        'prefix-1': words[index][0],\n",
        "        'prefix-2': words[index][:2],\n",
        "        'prefix-3': words[index][:3],\n",
        "        'suffix-1': words[index][-1],\n",
        "        'suffix-2': words[index][-2:],\n",
        "        'suffix-3': words[index][-3:],\n",
        "        'prev_word': '' if index == 0 else words[index - 1],\n",
        "        'next_word': '' if index == len(words) - 1 else words[index + 1],\n",
        "        'has_hyphen': '-' in words[index],\n",
        "        'is_numeric': words[index].isdigit(),\n",
        "        'capitals_inside': words[index][1:].lower() != words[index][1:]\n",
        "    }\n",
        "\n",
        "# Function to train a Naive Bayes POS tagger\n",
        "def train_naive_bayes_pos_tagger():\n",
        "    # Loading the Treebank corpus\n",
        "    tagged_sentences = treebank.tagged_sents()\n",
        "\n",
        "    # Splitting data into training and testing sets\n",
        "    train_size = int(len(tagged_sentences) * 0.8)\n",
        "    train_data = tagged_sentences[:train_size]\n",
        "    test_data = tagged_sentences[train_size:]\n",
        "\n",
        "    # Extracting features from the training data\n",
        "    train_features = []\n",
        "    for sentence in train_data:\n",
        "        words, tags = zip(*sentence)\n",
        "        for i in range(len(words)):\n",
        "            train_features.append((word_features(words, i), tags[i]))\n",
        "\n",
        "    # Training the Naive Bayes classifier based POS tagger\n",
        "    classifier = nltk.NaiveBayesClassifier.train(train_features)\n",
        "\n",
        "    # Creating the ClassifierBasedPOSTagger\n",
        "    tagger = ClassifierBasedPOSTagger(classifier=classifier)\n",
        "\n",
        "    #Evaluating accuracy on test data\n",
        "    test_features = []\n",
        "    for sentence in test_data:\n",
        "        words, tags = zip(*sentence)\n",
        "        for i in range(len(words)):\n",
        "            test_features.append((word_features(words, i), tags[i]))\n",
        "\n",
        "    accuracy = nltk.classify.accuracy(classifier, test_features)\n",
        "    print(\"Accuracy of Naive Bayes classifier based POS tagger :\", accuracy)\n",
        "\n",
        "    return tagger\n",
        "#### END CODE ####\n"
      ],
      "metadata": {
        "id": "zsFIKF3QetPp"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate rule-based POS tagger\n",
        "def evaluate_rule_based_pos_tagger(test_sents):\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    for sent in test_sents:\n",
        "        words = [word for word, tag in sent]\n",
        "        true_tags = [tag for word, tag in sent]\n",
        "        predicted_tags = [tag for word, tag in updated_rule_based_pos_tagger(' '.join(words))]\n",
        "        for true_tag, predicted_tag in zip(true_tags, predicted_tags):\n",
        "            total += 1\n",
        "            if true_tag == predicted_tag:\n",
        "                correct += 1\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Load the test data\n",
        "test_sents = treebank.tagged_sents()[3000:3200]\n"
      ],
      "metadata": {
        "id": "h3Dg6cINQM9e"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show printed output below\n",
        "sentence = \"The quick brown fox jumps over the lazy dog while it's raining heavily.\"\n",
        "\"\"\"your POS tagging function\"\"\"\n",
        "\n",
        "# Apply rule-based POS tagger\n",
        "rule_based_tags = updated_rule_based_pos_tagger(sentence)\n",
        "print(\"Rule-based POS Tags:\")\n",
        "print(rule_based_tags)\n",
        "\n",
        "# Evaluate the rule-based POS tagger\n",
        "accuracy = evaluate_rule_based_pos_tagger(test_sents)\n",
        "print(\"Rule-based POS Tagger Accuracy:\", accuracy)\n",
        "\n",
        "# Training the Naive Bayes POS tagger\n",
        "tagger = train_naive_bayes_pos_tagger()\n",
        "tagged_text = tagger.tag(nltk.word_tokenize(sentence))\n",
        "print(\"Naive Bayes POS Tags:\")\n",
        "print(tagged_text)\n",
        "\n",
        "# Apply NLTK's built-in POS tagger\n",
        "nltk_tags = nltk.pos_tag(word_tokenize(sentence))\n",
        "print(\"NLTK Built-in POS Tags:\")\n",
        "print(nltk_tags)"
      ],
      "metadata": {
        "id": "v3qmcVF6hxrR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "093c95b2-8110-4a80-d90a-097400424388"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule-based POS Tags:\n",
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'JJ'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('while', 'IN'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('raining', 'VBG'), ('heavily', 'RB'), ('.', '.')]\n",
            "Rule-based POS Tagger Accuracy: 0.06599298824499897\n",
            "Accuracy of Naive Bayes classifier based POS tagger : 0.9299865262737661\n",
            "Naive Bayes POS Tags:\n",
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'NN'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'NN'), ('dog', 'NN'), ('while', 'IN'), ('it', 'PRP'), (\"'s\", 'POS'), ('raining', 'NN'), ('heavily', 'RB'), ('.', '.')]\n",
            "NLTK Built-in POS Tags:\n",
            "[('The', 'DT'), ('quick', 'JJ'), ('brown', 'NN'), ('fox', 'NN'), ('jumps', 'VBZ'), ('over', 'IN'), ('the', 'DT'), ('lazy', 'JJ'), ('dog', 'NN'), ('while', 'IN'), ('it', 'PRP'), (\"'s\", 'VBZ'), ('raining', 'VBG'), ('heavily', 'RB'), ('.', '.')]\n"
          ]
        }
      ]
    }
  ]
}